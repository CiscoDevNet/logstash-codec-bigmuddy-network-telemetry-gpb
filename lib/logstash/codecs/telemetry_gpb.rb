# encoding: utf-8
#
require "logstash/codecs/base"
require "logstash/namespace"
require 'json'

def telemetry_gpb_camelise s
  s.split('_').collect {|w| w.capitalize}.join
end

def telemetry_gpb_extract_cisco_extensions_from_proto protofile
  #
  # Function takes care of returning the mapping between schema path
  # and corresponding class or module::class.
  #
  # We rely on the properties of the autogenerated .proto file.  We
  # expect to find at most one pertinent 'package' instruction in the
  # .proto file, and we expect one piece of metadata which talks about
  # paths and schema paths.
  #
  modulenames = nil
  classname = nil
  path = nil
  theclass = nil

  f = File.open(protofile, "r")
  f.each do |line|

    #
    # Extract module - this is important to protect against name space
    # pollution (e.g. where multiple sysdb bags point at the same bag)
    #
    m = line.match('package \s*(?<modulename>[\w\.]+)\s*;') 
    if m and m['modulename']
      modulenames = m['modulename'].split('.').map do |raw|
        #
        # We could camelise, but then RootOper becomes Rootoper which
        # is not what protouf compiler does.
        #
        telemetry_gpb_camelise raw
        #raw
      end
    end

    #
    # Extract bag name and path from metadata.
    #
    m = line.match('.*metadata.*\\\"bag\\\": \\\"(?<bag>[\d\w]*)\\\".*\\\"schema_path\\\": \\\"(?<path>[\d\w\.]*)\\\".*') 
    if m and m['bag'] and m['path']
      classname = telemetry_gpb_camelise m['bag']
      path = m['path']
    end

  end # End of line by line iteration on file.

  f.close

  if path and classname
    mod = Kernel
    if modulenames
      modulenames.each do |modulename|
        mod = mod.const_get(modulename)
      end
    end
    theclass = mod.const_get(classname)
  end

  if theclass
    return [path, [theclass, classname]]
  end

end

#
# To turn on debugging, modify LS_OPTS in /etc/default/logstash to
# LS_OPTS="--debug"
#
# To view debugs, look at the file pointed at by LS_LOG_FILE
# which defaults to /var/log/logstash/logstash.log
#
class LogStash::Codecs::Telemetry_gpb < LogStash::Codecs::Base
  config_name "telemetry_gpb"

  #
  # 'protofiles' specified path for directory holding:
  #
  # .proto files as generated on router, and post-processed
  # .pb.rb generated ruby bindings for the same
  #
  # e.g. protofiles => "/data/proto"
  #
  # If you do not plan to make backward incompatible
  # changes to the .proto file, you can also simply use
  # the full version on this side safe in the knowledge
  # that it will be able to read any subset you wish to
  # generate.
  #
  # In order to generate the Ruby bindings you will need
  # to use a protocol compiler which supports Ruby
  # bindings for proto2 (e.g. ruby-protocol-buffer gem)
  #
  config :protofiles, :validate => :path, :required => true

  public
  def register
    #
    # Initialise the state of the codec. Codec is always cloned from
    # this state.
    #
    @logger.info("Registering cisco telemetry_gpb dgram codec")

    #
    # Load ruby binding source files for .proto
    #
    Dir.glob(@protofiles + "/*.pb.rb") do |binding_sourcefile|
      dir_and_file = File.absolute_path binding_sourcefile
      @logger.info("Loading ruby source file",
                   :proto_binding_source => dir_and_file)
      begin
        load dir_and_file
      rescue Exception => e
        @logger.warn("Failed to load .proto Ruby binding source",
                     :proto_binding_source => dir_and_file,
                     :exception => e, :stacktrace => e.backtrace)
      end
    end

    #
    # Build a map of paths to gpb rb binding objects (and name)
    #
    # Sample outcome:
    #
    # @protofiles_map = {
    #  "RootOper.FIB.Node.Protocol.VRF.IPPrefixBrief" =>
    #      [FibShTblFib, "FibShTblFib"],
    #  "RootOper.InfraStatistics.Interface.Latest.GenericCounters" =>
    #      [IfstatsbagGeneric, "IfstatsbagGeneric"]
    #   ...
    # }
    #
    #
    @protofiles_map =
      Hash[Dir.glob(@protofiles + "/*.proto").map { |p|
             telemetry_gpb_extract_cisco_extensions_from_proto p
           }]
    @logger.info("Loading ruby path to class map",
                 :protofiles_map => @protofiles_map.to_s)

  end

  public
  def decode(data)

    connection_thread = Thread.current

    @logger.debug? &&
      @logger.debug("Transport passing data down",
                    :thread => connection_thread.to_s,
                    :length => data.length)

    msg = TelemetryHeader.new
    begin
      msg_out = msg.parse(data).to_hash
      tables = msg_out.delete(:tables)
      tables.each do |table|

        @logger.debug? &&
          @logger.debug("Message policy paths",
                        :identifier => msg_out[:identifier],
                        :policy_name => msg_out[:policy_name],
                        :end_time => msg_out[:end_time],
                        :policy_path => table[:policy_path])

        #
        # Map row to appropriate sub-message type and decode.
        #
        if @protofiles_map.has_key? table[:policy_path]
          row_decoder_name = @protofiles_map[table[:policy_path]]
          begin

            row_decoder_class = row_decoder_name[0]
            rows = table[:row]
            rows.each do |row|

              @logger.debug? &&
                @logger.debug("Raw row", :row_raw => row.to_s,
                              :row_decoder_name => row_decoder_name,
                              :row_decoder_class => row_decoder_class.to_s)

              #
              # Perhaps just clear the object as opposed to allocate
              # it for every iteration.
              #
              row_decoder = row_decoder_class.new
              row_out = row_decoder.parse(row).to_hash
              @logger.debug? &&
                @logger.debug("Decoded row",
                              :row_out => row_out.to_s)

              #
              # Merge header and row, stringify keys, and yield.
              #
              # Stringify operation copes with nested hashes too.
              # .stringify in rails is what I am looking for, but this
              # is not rails.
              #
              ev = msg_out.clone
              ev[:end_time] = msg_out[:end_time]
              ev[:content] = row_out
              ev[:type] = row_decoder_name[1]
              ev[:path] = table[:policy_path]
              yield LogStash::Event.new(JSON.parse(ev.to_json))

            end # End of iteration over rows

          rescue Exception => e
            @logger.warn("Failed to decode telemetry row",
                         :policy_path => table[:policy_path],
                         :decoder => row_decoder_name,
                         :exception => e, :stacktrace => e.backtrace)
          end # End of exception handling of row decode

          @logger.debug? && @logger.debug("Iteration end")

        else # No decoder is available

          @logger.debug? &&
            @logger.debug("No decoder available",
                          :policy_path => table[:policy_path])

        end # End of cases where a decoder is available, or not

      end # End of iteration over each table

    rescue Exception => e
      @logger.warn("Failed to decode telemetry header",
                   :data => data,
                   :exception => e, :stacktrace => e.backtrace)
    end

  end # def decode

  public
  def encode(event)
    # do nothing on encode for now
    @logger.info("cisco telemetry: no encode facility")
  end # def encode

end # class LogStash::Codecs::TelemetryStream
